{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import functools\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pandas\n",
    "import pickle\n",
    "from pprint import PrettyPrinter\n",
    "import pymongo\n",
    "import re\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'iati', 'local']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn=pymongo.MongoClient('mongodb', 27017)\n",
    "\n",
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organizations',\n",
       " 'activities',\n",
       " 'activities_metadata',\n",
       " 'transactions',\n",
       " 'organizations_metadata']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = conn.iati\n",
    "\n",
    "activities=db.activities\n",
    "\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764159\n"
     ]
    }
   ],
   "source": [
    "print(activities.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring all the activities out of MongoDB and into memory so that we can process them much faster. Iterating over the MongoDB collection takes minutes. Iterating over an in-memory version containing only the fields we're interested in takes seconds.\n",
    "\n",
    "However, we need a lot of memory to fit everything, so we'll only include a few of the fields which might be useful when constructing the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = set([\n",
    "    '@w210-key',\n",
    "    'reporting-org',\n",
    "    'participating-org',\n",
    "    'recipient-country',\n",
    "    'transaction'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31 18:55:01.675431 Started processing\n",
      "2017-12-31 18:55:01.688327 Processed 0 of 764159\n",
      "2017-12-31 18:55:07.639210 Processed 50000 of 764159\n",
      "2017-12-31 18:55:15.104585 Processed 100000 of 764159\n",
      "2017-12-31 18:55:21.930865 Processed 150000 of 764159\n",
      "2017-12-31 18:55:30.015696 Processed 200000 of 764159\n",
      "2017-12-31 18:55:38.334383 Processed 250000 of 764159\n",
      "2017-12-31 18:55:44.661114 Processed 300000 of 764159\n",
      "2017-12-31 18:55:52.034615 Processed 350000 of 764159\n",
      "2017-12-31 18:55:58.219051 Processed 400000 of 764159\n",
      "2017-12-31 18:56:09.044564 Processed 450000 of 764159\n",
      "2017-12-31 18:56:13.563898 Processed 500000 of 764159\n",
      "2017-12-31 18:56:20.703983 Processed 550000 of 764159\n",
      "2017-12-31 18:56:29.133042 Processed 600000 of 764159\n",
      "2017-12-31 18:56:38.101520 Processed 650000 of 764159\n",
      "2017-12-31 18:56:41.864497 Processed 700000 of 764159\n",
      "2017-12-31 18:56:51.083654 Processed 750000 of 764159\n",
      "2017-12-31 18:56:51.999599 Finished processing\n"
     ]
    }
   ],
   "source": [
    "all_activities = []\n",
    "activities_count = activities.count()\n",
    "\n",
    "print(datetime.now(), 'Started processing')\n",
    "\n",
    "for num, activity in enumerate(activities.find()):\n",
    "    if num % 50000 == 0:\n",
    "        print(datetime.now(), 'Processed', num, 'of', activities_count)\n",
    "\n",
    "    activity_copy = { key: value for key, value in activity.items() if key in fields }\n",
    "\n",
    "    all_activities.append(activity_copy)\n",
    "\n",
    "print(datetime.now(), 'Finished processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Adjacency List Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub('\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element, attribute):\n",
    "\n",
    "    if element is None:\n",
    "        return None\n",
    "\n",
    "    if attribute not in element:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        value = element[attribute]\n",
    "    except Exception as e:\n",
    "        print(element, attribute)\n",
    "        raise e\n",
    "\n",
    "    if type(value) == dict:\n",
    "        if '#text' in value:\n",
    "            return value['#text']\n",
    "\n",
    "        return None\n",
    "\n",
    "    if type(value) != list:\n",
    "        return value\n",
    "\n",
    "    return [\n",
    "        item['#text'] if type(item) == dict and '#text' in item else\n",
    "            None if type(item) == dict else item\n",
    "        for item in value\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_list(parent, field_keys):\n",
    "    value = parent\n",
    "\n",
    "    for key in field_keys:\n",
    "\n",
    "        # If we have a dictionary, we simply access the attribute\n",
    "\n",
    "        if type(value) == dict:\n",
    "            if key not in value:\n",
    "                return []\n",
    "\n",
    "            value = value[key]\n",
    "            continue\n",
    "\n",
    "        # If we have something that is neither a dict nor a list, we\n",
    "        # cannot navigate further down the JSON object, so we were\n",
    "        # unable to find what we needed.\n",
    "\n",
    "        if type(value) != list:\n",
    "            return []\n",
    "\n",
    "        # If we have a list, then we'll check the key in each element\n",
    "        # of the list.\n",
    "\n",
    "        value = [ item[key] for item in value if item is not None and key in item ]\n",
    "\n",
    "    if value is None:\n",
    "        return []\n",
    "\n",
    "    if type(value) != list:\n",
    "        value = [value]\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_list(\n",
    "    activity, field_keys, left_element, left_child, right_element, right_child,\n",
    "    left_reporting_org_fallback, right_reporting_org_fallback):\n",
    "\n",
    "    node_list = get_node_list(activity, field_keys)\n",
    "\n",
    "    return_value = []\n",
    "\n",
    "    left_fallback = None\n",
    "\n",
    "    if left_reporting_org_fallback is not None:\n",
    "        left = get_node_list(activity, ['reporting-org'])\n",
    "        left_fallback = get_text(left[0], left_reporting_org_fallback)\n",
    "\n",
    "    right_fallback = None\n",
    "\n",
    "    if right_reporting_org_fallback is not None:\n",
    "        right = get_node_list(activity, ['reporting-org'])\n",
    "        right_fallback = get_text(right[0], right_reporting_org_fallback)\n",
    "\n",
    "    for node in node_list:\n",
    "        if left_element not in node or right_element not in node:\n",
    "            continue\n",
    "\n",
    "        left = get_node_list(node, [left_element])\n",
    "        right = get_node_list(node, [right_element])\n",
    "\n",
    "        for left_node, right_node in itertools.product(left, right):\n",
    "            left_list = get_text(left_node, left_child)\n",
    "            right_list = get_text(right_node, right_child)\n",
    "\n",
    "            if left_list is None:\n",
    "                left_list = left_fallback\n",
    "\n",
    "            if right_list is None:\n",
    "                right_list = right_fallback\n",
    "\n",
    "            if left_list is None or right_list is None:\n",
    "                continue\n",
    "\n",
    "            if type(left_list) != list:\n",
    "                left_list = [left_list]\n",
    "\n",
    "            if type(right_list) != list:\n",
    "                right_list = [right_list]\n",
    "\n",
    "            return_value += [\n",
    "                (activity['@w210-key'], clean_text(left_value), clean_text(right_value))\n",
    "                    for left_value, right_value in itertools.product(left_list, right_list)\n",
    "                        if left_value is not None and right_value is not None\n",
    "            ]\n",
    "\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(\n",
    "    field_path, left_element, left_child, right_element, right_child,\n",
    "    left_reporting_org_fallback = None, right_reporting_org_fallback = None):\n",
    "\n",
    "    if field_path is None:\n",
    "        field_keys = []\n",
    "    else:\n",
    "        field_keys = field_path.split('.')\n",
    "\n",
    "    return_values = []\n",
    "\n",
    "    for activity in all_activities:\n",
    "        new_values = get_edge_list(\n",
    "            activity, field_keys, left_element, left_child, right_element, right_child,\n",
    "            left_reporting_org_fallback, right_reporting_org_fallback)\n",
    "\n",
    "        return_values += new_values\n",
    "\n",
    "    return return_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph from Root Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_edges_ref = get_edges(\n",
    "    None, 'reporting-org', '@ref', 'participating-org', '@ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_edges_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_root_ref.txt', 'wb') as f:\n",
    "    pickle.dump(root_edges_ref, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_edges_narrative = get_edges(\n",
    "    None, 'reporting-org', 'narrative', 'participating-org', 'narrative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2442966"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_edges_narrative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_root_narrative.txt', 'wb') as f:\n",
    "    pickle.dump(root_edges_ref, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph from Transaction Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_edges_ref = get_edges(\n",
    "    'transaction', 'provider-org', '@ref', 'receiver-org', '@ref', '@ref', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658076"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transaction_edges_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_transaction_ref.txt', 'wb') as f:\n",
    "    pickle.dump(transaction_edges_ref, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_edges_narrative = get_edges(\n",
    "    'transaction', 'provider-org', 'narrative', 'receiver-org', 'narrative', 'narrative', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041716"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transaction_edges_narrative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_transaction_narrative.txt', 'wb') as f:\n",
    "    pickle.dump(root_edges_ref, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph from Recipient Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipient_edges_ref = get_edges(\n",
    "    None, 'recipient-country', '@code', 'reporting-org', '@ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615047"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipient_edges_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_country_ref.txt', 'wb') as f:\n",
    "    pickle.dump(recipient_edges_ref, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph Files from Adjacency Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to convert these `.txt` files into actual graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_id(node_ids, name):\n",
    "\n",
    "    # Increment the counter if we haven't seen it\n",
    "\n",
    "    if name not in node_ids:\n",
    "        node_ids[name] = len(node_ids)\n",
    "\n",
    "    return node_ids[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(file_name):\n",
    "    node_ids = {}\n",
    "\n",
    "    get_graph_node_id = functools.partial(get_node_id, node_ids)\n",
    "\n",
    "    # Iterate once in order to initialize the node ID dictionary\n",
    "\n",
    "    print(datetime.now(), 'Identifying nodes in', file_name)\n",
    "\n",
    "    with open(file_name, 'rb') as graph_file:\n",
    "        edges = pickle.load(graph_file)\n",
    "\n",
    "        for activity_file, source_name, target_name in edges:\n",
    "            source_id = get_graph_node_id(source_name)\n",
    "            target_id = get_graph_node_id(target_name)\n",
    "\n",
    "    node_count = len(node_ids)\n",
    "\n",
    "    graph_matrix = dok_matrix((node_count, node_count))\n",
    "\n",
    "    print(datetime.now(), 'Building sparse matrix for', file_name)\n",
    "\n",
    "    # Iterate again in order to populate the sparse matrix\n",
    "\n",
    "    with open(file_name, 'rb') as graph_file:\n",
    "        edges = pickle.load(graph_file)\n",
    "\n",
    "        for activity_file, source_name, target_name in edges:\n",
    "            source_id = get_graph_node_id(source_name)\n",
    "            target_id = get_graph_node_id(target_name)\n",
    "\n",
    "            graph_matrix[source_id, target_id] += 1\n",
    "\n",
    "    print(datetime.now(), 'Finished processing', file_name)\n",
    "\n",
    "    return node_ids, graph_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Dangling Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dangling_nodes(check_axis, graph_ids, graph):\n",
    "\n",
    "    # Create a reverse lookup table\n",
    "\n",
    "    graph_names = { value: key for key, value in graph_ids.items() }\n",
    "\n",
    "    # Sum by the axis and identify the non-zero entries\n",
    "\n",
    "    sums = graph.sum(axis = check_axis)\n",
    "    sums = sums.reshape((sums.shape[1 - check_axis], 1))\n",
    "\n",
    "    return [graph_names[index] for index, value in enumerate(sums) if value == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_source_nodes = functools.partial(get_dangling_nodes, 0)\n",
    "get_sink_nodes = functools.partial(get_dangling_nodes, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run against All Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir('.'):\n",
    "    if len(file_name) > 4 and file_name[-4:] == '.ids':\n",
    "        os.remove(file_name)\n",
    "    elif len(file_name) > 6 and file_name[-6:] == '.graph':\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31 19:01:38.420353 Loading graph for graph_root_narrative.txt\n",
      "2017-12-31 19:01:38.420487 Identifying nodes in graph_root_narrative.txt\n",
      "2017-12-31 19:01:39.549823 Building sparse matrix for graph_root_narrative.txt\n",
      "2017-12-31 19:02:08.120678 Finished processing graph_root_narrative.txt\n",
      "2017-12-31 19:02:08.341382 Loading graph for graph_root_ref.txt\n",
      "2017-12-31 19:02:08.341453 Identifying nodes in graph_root_ref.txt\n",
      "2017-12-31 19:02:09.492791 Building sparse matrix for graph_root_ref.txt\n",
      "2017-12-31 19:02:38.130612 Finished processing graph_root_ref.txt\n",
      "2017-12-31 19:02:38.353757 Loading graph for graph_transaction_narrative.txt\n",
      "2017-12-31 19:02:38.353828 Identifying nodes in graph_transaction_narrative.txt\n",
      "2017-12-31 19:02:39.422285 Building sparse matrix for graph_transaction_narrative.txt\n",
      "2017-12-31 19:03:05.828895 Finished processing graph_transaction_narrative.txt\n",
      "2017-12-31 19:03:06.058151 Loading graph for graph_country_ref.txt\n",
      "2017-12-31 19:03:06.058221 Identifying nodes in graph_country_ref.txt\n",
      "2017-12-31 19:03:06.413233 Building sparse matrix for graph_country_ref.txt\n",
      "2017-12-31 19:03:14.059223 Finished processing graph_country_ref.txt\n",
      "2017-12-31 19:03:14.113261 Loading graph for graph_transaction_ref.txt\n",
      "2017-12-31 19:03:14.113337 Identifying nodes in graph_transaction_ref.txt\n",
      "2017-12-31 19:03:14.407051 Building sparse matrix for graph_transaction_ref.txt\n",
      "2017-12-31 19:03:22.732271 Finished processing graph_transaction_ref.txt\n"
     ]
    }
   ],
   "source": [
    "graph_stats = []\n",
    "graph_data = []\n",
    "\n",
    "for file_name in os.listdir('.'):\n",
    "    if file_name[0:5] != 'graph' or file_name[-4:] != '.txt':\n",
    "        continue\n",
    "\n",
    "    # Load the file from cache if we've already done the computation once\n",
    "\n",
    "    if os.path.isfile(file_name + '.ids') and os.path.isfile(file_name + '.graph'):\n",
    "        print(datetime.now(), 'Loading cached graph for', file_name)\n",
    "\n",
    "        with open(file_name + '.ids', 'rb') as id_file:\n",
    "            graph_ids = pickle.load(id_file)\n",
    "\n",
    "        with open(file_name + '.graph', 'rb') as graph_file:\n",
    "            graph = pickle.load(graph_file)\n",
    "\n",
    "    # Otherwise, perform the computation and save the resulting computations\n",
    "\n",
    "    else:\n",
    "        print(datetime.now(), 'Loading graph for', file_name)\n",
    "\n",
    "        graph_ids, graph = load_graph(file_name)\n",
    "\n",
    "        with open(file_name + '.ids', 'wb') as id_file:\n",
    "            pickle.dump(graph_ids, id_file)\n",
    "\n",
    "        with open(file_name + '.graph', 'wb') as graph_file:\n",
    "            pickle.dump(graph, graph_file)\n",
    "\n",
    "    source_nodes = get_source_nodes(graph_ids, graph)\n",
    "    sink_nodes = get_sink_nodes(graph_ids, graph)\n",
    "\n",
    "    graph_stats.append({\n",
    "        'graph file': file_name,\n",
    "        'total nodes': len(graph_ids),\n",
    "        'has both edges': len(graph_ids) - len(source_nodes) - len(sink_nodes),\n",
    "        'has only outgoing edges': len(source_nodes),\n",
    "        'has only incoming edges': len(sink_nodes)\n",
    "    })\n",
    "\n",
    "    graph_data.append({\n",
    "        'file': file_name,\n",
    "        'graph': graph,\n",
    "        'all_nodes': graph_ids,\n",
    "        'source_nodes': source_nodes,\n",
    "        'sink_nodes': sink_nodes\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph file</th>\n",
       "      <th>has both edges</th>\n",
       "      <th>has only incoming edges</th>\n",
       "      <th>has only outgoing edges</th>\n",
       "      <th>total nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graph_root_narrative.txt</td>\n",
       "      <td>293</td>\n",
       "      <td>11451</td>\n",
       "      <td>67</td>\n",
       "      <td>11811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graph_root_ref.txt</td>\n",
       "      <td>293</td>\n",
       "      <td>11451</td>\n",
       "      <td>67</td>\n",
       "      <td>11811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graph_transaction_narrative.txt</td>\n",
       "      <td>293</td>\n",
       "      <td>11451</td>\n",
       "      <td>67</td>\n",
       "      <td>11811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>graph_country_ref.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>363</td>\n",
       "      <td>432</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>graph_transaction_ref.txt</td>\n",
       "      <td>341</td>\n",
       "      <td>2762</td>\n",
       "      <td>1979</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        graph file  has both edges  has only incoming edges  \\\n",
       "0         graph_root_narrative.txt             293                    11451 \n",
       "1               graph_root_ref.txt             293                    11451 \n",
       "2  graph_transaction_narrative.txt             293                    11451 \n",
       "3            graph_country_ref.txt               1                      363 \n",
       "4        graph_transaction_ref.txt             341                     2762 \n",
       "\n",
       "   has only outgoing edges  total nodes\n",
       "0                       67        11811\n",
       "1                       67        11811\n",
       "2                       67        11811\n",
       "3                      432          796\n",
       "4                     1979         5082  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(graph_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
